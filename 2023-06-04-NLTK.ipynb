{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b079d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "import nltk\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk import pos_tag\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46dc2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to stopwords\n",
    "standard_stopwords = set(stopwords.words('english'))\n",
    "additional_stopwords = set(['.', ',', ';', ':', '!', '?',')','('])\n",
    "\n",
    "# Combine the default stopwords with the additional stopwords\n",
    "stop_words = standard_stopwords.union(additional_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d64eeac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#planapps\n",
    "planapp_data = pd.read_csv(\"C:\\\\Users\\paton\\\\Documents\\\\_Glasgow Univ MSc\\\\_yr2_dissertation\\\\data\\\\ccf_planapp_pol.csv\")\n",
    "#ldps\n",
    "planldp_data = pd.read_csv(\"C:\\\\Users\\paton\\\\Documents\\\\_Glasgow Univ MSc\\\\_yr2_dissertation\\\\data\\\\ldps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a61442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "planapp_data[\"text\"] = planapp_data[\"proposal\"]\n",
    "planldp_data[\"text\"] = planldp_data[\"_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ef962f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "planapp_data['tokens'] = planapp_data[\"text\"].apply(lambda x: word_tokenize(str(x)) if isinstance(x, str) else [])\n",
    "planldp_data['tokens'] = planldp_data[\"text\"].apply(lambda x: word_tokenize(str(x)) if isinstance(x, str) else [])\n",
    "#using tags to classify\n",
    "#tagged_tokens = pos_tag(tokens)\n",
    "#def extract_features(tagged_tokens):\n",
    "#    features = {}\n",
    "#    for word, tag in tagged_tokens:\n",
    "#        features['pos_' + tag] = True\n",
    "#    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "905e4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "planapp_filtered_tokens = [token for tokens in planapp_data['tokens'] for token in tokens if token.lower() not in stop_words]\n",
    "planldp_filtered_tokens = [token for tokens in planldp_data['tokens'] for token in tokens if token.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ce29d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Erection', 'extension', 'rear', 'dwellinghouse', 'existing', 'storey', 'house', 'Alterations', 'new', 'Installation', 'alterations', 'single', 'use', 'garage', 'Extension', 'Change', 'erection', '2', 'associated', 'building', '-', 'Dwellinghouse', 'access', 'side', 'form', '1', 'windows', 'installation', 'front', 'replacement', 'dwelling', 'roof', 'Proposed', 'Class', 'formation', 'including', '3', 'two', 'external', 'window', 'Formation', 'works', 'garden', 'Use', 'planning', 'Erect', 'floor', 'area', 'Planning', 'dormer', 'illuminated', 'parking', 'permission', 'elevation', 'Demolition', '&', 'ground', '4', 'Single', 'door', 'Replacement', 'ERECTION', 'wall', 'room', 'detached', 'sign', 'residential', 'one', 'internal', 'consent', 'tree', 'doors', 'car', 'accommodation', 'Internal', 'development', 'Display', 'timber', 'DWELLINGHOUSE', 'property', 'unit', 'conservatory', 'storage', 'Building', 'landscaping', 'flat', 'change', 'Permission', 'units', 'proposed', 'office', 'ancillary', 'agricultural', 'Garage', 'House', 'Removal', 'boundary', 'retrospective', 'Conversion', 'height']\n"
     ]
    }
   ],
   "source": [
    "freq_dist = FreqDist(planapp_filtered_tokens)\n",
    "top_keywords = freq_dist.most_common(100)\n",
    "keywords = [keyword for keyword, count in top_keywords]\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b30ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Centre', 'Housing', 'Green', 'Site', '-', 'Space', 'Area', 'Town', 'Network', 'Mixed', '&', 'Business', 'Use', 'Land', 'Areas', 'Retail', 'Open', 'Urban', 'Community', 'Local', 'Plan', 'Development', 'Park', 'Facilities', 'Commercial', 'Residential', 'SWT', 'Wildlife', 'Existing', 'Zone', 'Employment', 'Industrial', 'Neighbourhood', 'Sites', 'Transport', 'General', 'Core', 'Strategic', 'City', 'Economic', 'LDP', 'LDP_region', 'Policy', 'Protection', 'Long', 'Term', 'Conservation', 'Reserve', 'Industry', 'SSSI', 'Class', 'Harbour', 'Settlement', 'Belt', 'houses', '1', 'Special', 'Countryside', 'New', 'Nature', 'Education', 'Greenbelt', '2020', 'LNCS', 'Facility', 'Rural', 'Amenity', 'Opportunity', 'Proposed', 'Airport', 'Release', 'space', 'Energy', 'East', 'granted', 'OLV', 'Aberdeen', 'Country', 'Principal', 'Growth', 'LLT', 'Waste', 'Centres', 'use', 'Safeguard', 'Tourism', 'Proposals', 'Woodland', 'Natural', 'Road', 'centre', 'access', 'Permission', 'STRAT1', 'Committed', 'safeguard', 'Glasgow', 'ï¿½', 'Allocation', 'Level']\n"
     ]
    }
   ],
   "source": [
    "freq_dist = FreqDist(planldp_filtered_tokens)\n",
    "top_keywords = freq_dist.most_common(100)\n",
    "keywords = [keyword for keyword, count in top_keywords]\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d16ed772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to apply tokens as new column\n",
    "def extract_tokens(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c9e77bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gid  year         keyval     reference alt_ref       local_auth  plan_auth  \\\n",
      "0    1  2009  KHBMSNCH0C900  09/00400/DET     NaN  Argyll and Bute        NaN   \n",
      "1    2  2009  KHQ1PMCH02Z00  09/00444/DET     NaN  Argyll and Bute        NaN   \n",
      "2    3  2009  KHQ711CH02Z00  09/00447/DET     NaN  Argyll and Bute        NaN   \n",
      "3    4  2009  KHQ85UCH0BJ00  09/00449/DET     NaN  Argyll and Bute        NaN   \n",
      "4    5  2009  KHS28ACH0BJ00  09/00466/ADV     NaN  Argyll and Bute        NaN   \n",
      "\n",
      "                                                 url         uprn  \\\n",
      "0  https://publicaccess.argyll-bute.gov.uk/online...  125052044.0   \n",
      "1  https://publicaccess.argyll-bute.gov.uk/online...  125059932.0   \n",
      "2  https://publicaccess.argyll-bute.gov.uk/online...  125059932.0   \n",
      "3  https://publicaccess.argyll-bute.gov.uk/online...  125063585.0   \n",
      "4  https://publicaccess.argyll-bute.gov.uk/online...  125067382.0   \n",
      "\n",
      "                                             address  ...  \\\n",
      "0  Kirkhouse, Muasdale, Tarbert, Argyll And Bute,...  ...   \n",
      "1  Garden Ground , The Sheiling, Millhouse, Tighn...  ...   \n",
      "2  The Sheiling, Millhouse, Tighnabruaich, Argyll...  ...   \n",
      "3      Melfort Pier, Kilmelford, Argyll And Bute, ,   ...   \n",
      "4  The Craignure Stores, Craignure, Isle Of Mull,...  ...   \n",
      "\n",
      "               stat_desc  date_adver  date_adexp    xcoord    ycoord data_src  \\\n",
      "0  Application Permitted  2009-04-24  2009-05-08  168393.0  641380.0      CCF   \n",
      "1    Application Refused  2009-04-17  2009-05-08  193079.0  669110.0      CCF   \n",
      "2  Application Permitted         NaN         NaN  193133.0  669125.0      CCF   \n",
      "3    Application Refused  2009-04-16  2009-04-30  183237.0  714094.0      CCF   \n",
      "4  Application Permitted         NaN         NaN  171741.0  737159.0      CCF   \n",
      "\n",
      "    sh_update                                               text  \\\n",
      "0  2023-05-26  Erection of dwelling house within existing chu...   \n",
      "1  2023-05-26              Erection of two holiday letting units   \n",
      "2  2023-05-26  Erection of extension with balcony and formati...   \n",
      "3  2023-05-26                Proposed erection of managers house   \n",
      "4  2023-05-26                     Proposed erection of signboard   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  [Erection, of, dwelling, house, within, existi...   \n",
      "1       [Erection, of, two, holiday, letting, units]   \n",
      "2  [Erection, of, extension, with, balcony, and, ...   \n",
      "3          [Proposed, erection, of, managers, house]   \n",
      "4                [Proposed, erection, of, signboard]   \n",
      "\n",
      "                                     proposal_tokens  \n",
      "0  [Erection, of, dwelling, house, within, existi...  \n",
      "1       [Erection, of, two, holiday, letting, units]  \n",
      "2  [Erection, of, extension, with, balcony, and, ...  \n",
      "3          [Proposed, erection, of, managers, house]  \n",
      "4                [Proposed, erection, of, signboard]  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "attribute_columns = ['proposal']  # Replace with your attribute column names\n",
    "\n",
    "for column in attribute_columns:\n",
    "    new_column_name = column + '_tokens'\n",
    "    planapp_data[new_column_name] = planapp_data[column].apply(lambda x: extract_tokens(str(x)) if isinstance(x, str) else [])\n",
    "\n",
    "print(planapp_data.head())  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6be348b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   _type      local_authority  \\\n",
      "0  LDP2_-_Additional_Housing_Allocations       North Ayrshire   \n",
      "1                         SSSI Loch Libo    East Renfrewshire   \n",
      "2                    Commercial,Business       South Ayrshire   \n",
      "3                                    SPZ         Renfrewshire   \n",
      "4                  LDP2_PP_Plan_Boundary  West Dunbartonshire   \n",
      "\n",
      "   _type.total_count                                   text  \\\n",
      "0                  8  LDP2_-_Additional_Housing_Allocations   \n",
      "1                  1                         SSSI Loch Libo   \n",
      "2                  2                    Commercial,Business   \n",
      "3                  2                                    SPZ   \n",
      "4                  1                  LDP2_PP_Plan_Boundary   \n",
      "\n",
      "                                    tokens  \\\n",
      "0  [LDP2_-_Additional_Housing_Allocations]   \n",
      "1                       [SSSI, Loch, Libo]   \n",
      "2                [Commercial, ,, Business]   \n",
      "3                                    [SPZ]   \n",
      "4                  [LDP2_PP_Plan_Boundary]   \n",
      "\n",
      "                              _type_tokens  \n",
      "0  [LDP2_-_Additional_Housing_Allocations]  \n",
      "1                       [SSSI, Loch, Libo]  \n",
      "2                [Commercial, ,, Business]  \n",
      "3                                    [SPZ]  \n",
      "4                  [LDP2_PP_Plan_Boundary]  \n"
     ]
    }
   ],
   "source": [
    "# to apply tokens as new column\n",
    "\n",
    "attribute_columns = ['_type']  # Replace with your attribute column names\n",
    "\n",
    "for column in attribute_columns:\n",
    "    new_column_name = column + '_tokens'\n",
    "    planldp_data[new_column_name] = planldp_data[column].apply(extract_tokens)\n",
    "\n",
    "print(planldp_data.head())  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ba3a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "planldp_data.to_csv('ldpoutput.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b183414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier - likely to classify based upon extracted tokens column\n",
    "#need to extract aggregates and minerals maybe at conclusion of process to prove feasibility\n",
    "\n",
    "\n",
    "# Training data\n",
    "labeled_data = [\n",
    "    (\"This is a good product\", \"positive\"),\n",
    "    (\"I do not like this item\", \"negative\"),\n",
    "    (\"The service was excellent\", \"positive\"),\n",
    "    (\"The quality needs improvement\", \"negative\")\n",
    "]\n",
    "\n",
    "# Prepare the training set\n",
    "training_set = [(extract_features(pos_tag(word_tokenize(text))), label) for text, label in labeled_data]\n",
    "\n",
    "# Train the classifier\n",
    "classifier = NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "\n",
    "document_features = extract_features(tagged_tokens)\n",
    "predicted_label = classifier.classify(document_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
